diff --git a/configs/_base_/datasets/suadd23.py b/configs/_base_/datasets/suadd23.py
new file mode 100644
index 0000000..195e271
--- /dev/null
+++ b/configs/_base_/datasets/suadd23.py
@@ -0,0 +1,56 @@
+# dataset settings
+dataset_type = 'SUADDDataset'
+data_root = 'data/suadd23/'
+img_suffix = '.png'
+
+img_norm_cfg = dict(
+    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
+crop_size = (1024, 1024)
+train_pipeline = [
+    dict(type='LoadImageFromFile'),
+    dict(type='LoadAnnotations'),
+    dict(type='Resize', img_scale=(1550, 2200), ratio_range=(0.5, 2.0)),
+    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.75),
+    dict(type='RandomFlip', prob=0.5),
+    dict(type='PhotoMetricDistortion'),
+    dict(type='Normalize', **img_norm_cfg),
+    dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),
+    dict(type='DefaultFormatBundle'),
+    dict(type='Collect', keys=['img', 'gt_semantic_seg']),
+]
+test_pipeline = [
+    dict(type='LoadImageFromFile'),
+    dict(
+        type='MultiScaleFlipAug',
+        img_scale=(1550, 2200),
+        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],
+        flip=False,
+        transforms=[
+            dict(type='Resize', keep_ratio=True),
+            dict(type='RandomFlip'),
+            dict(type='Normalize', **img_norm_cfg),
+            dict(type='ImageToTensor', keys=['img']),
+            dict(type='Collect', keys=['img']),
+        ])
+]
+data = dict(
+    samples_per_gpu=2,
+    workers_per_gpu=2,
+    train=dict(
+        type=dataset_type,
+        data_root=data_root,
+        img_dir='inputs/train',
+        ann_dir='semantic_annotations/train',
+        pipeline=train_pipeline),
+    val=dict(
+        type=dataset_type,
+        data_root=data_root,
+        img_dir='inputs/val',
+        ann_dir='semantic_annotations/val',
+        pipeline=test_pipeline),
+    test=dict(
+        type=dataset_type,
+        data_root=data_root,
+        img_dir='inputs/val',
+        ann_dir='semantic_annotations/val',
+        pipeline=test_pipeline))
diff --git a/configs/segformer/segformer_mit-b0_8x1_1024x1024_160k_suadd.py b/configs/segformer/segformer_mit-b0_8x1_1024x1024_160k_suadd.py
new file mode 100644
index 0000000..508f966
--- /dev/null
+++ b/configs/segformer/segformer_mit-b0_8x1_1024x1024_160k_suadd.py
@@ -0,0 +1,40 @@
+_base_ = [
+    '../_base_/models/segformer_mit-b0.py',
+    '../_base_/datasets/suadd23.py',
+    '../_base_/default_runtime.py', '../_base_/schedules/schedule_160k.py'
+]
+
+checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b0_20220624-7e0fe6dd.pth'  # noqa
+
+model = dict(
+    backbone=dict(init_cfg=dict(type='Pretrained', checkpoint=checkpoint)),
+    test_cfg=dict(mode='slide', crop_size=(1024, 1024), stride=(768, 768)))
+
+# optimizer
+optimizer = dict(
+    _delete_=True,
+    type='AdamW',
+    lr=0.00006,
+    betas=(0.9, 0.999),
+    weight_decay=0.01,
+    paramwise_cfg=dict(
+        custom_keys={
+            'pos_block': dict(decay_mult=0.),
+            'norm': dict(decay_mult=0.),
+            'head': dict(lr_mult=10.)
+        }))
+
+lr_config = dict(
+    _delete_=True,
+    policy='poly',
+    warmup='linear',
+    warmup_iters=1500,
+    warmup_ratio=1e-6,
+    power=1.0,
+    min_lr=0.0,
+    by_epoch=False)
+
+data = dict(samples_per_gpu=1, workers_per_gpu=1)
+
+workflow = [('train', 1), ('val', 1)]
+#evaluation = dict(interval=1, metric='mIoU')
\ No newline at end of file
diff --git a/configs/segformer/segformer_mit-b5_8x1_1024x1024_160k_suadd.py b/configs/segformer/segformer_mit-b5_8x1_1024x1024_160k_suadd.py
new file mode 100644
index 0000000..05bed38
--- /dev/null
+++ b/configs/segformer/segformer_mit-b5_8x1_1024x1024_160k_suadd.py
@@ -0,0 +1,9 @@
+_base_ = ['./segformer_mit-b0_8x1_1024x1024_160k_suadd.py']
+
+checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'  # noqa
+model = dict(
+    backbone=dict(
+        init_cfg=dict(type='Pretrained', checkpoint=checkpoint),
+        embed_dims=64,
+        num_layers=[3, 6, 40, 3]),
+    decode_head=dict(in_channels=[64, 128, 320, 512]))
\ No newline at end of file
diff --git a/mmseg/datasets/__init__.py b/mmseg/datasets/__init__.py
index 9060564..94181c5 100644
--- a/mmseg/datasets/__init__.py
+++ b/mmseg/datasets/__init__.py
@@ -19,6 +19,7 @@ from .pascal_context import PascalContextDataset, PascalContextDataset59
 from .potsdam import PotsdamDataset
 from .stare import STAREDataset
 from .voc import PascalVOCDataset
+from .suadd23 import SUADDDataset
 
 __all__ = [
     'CustomDataset', 'build_dataloader', 'ConcatDataset', 'RepeatDataset',
@@ -27,5 +28,5 @@ __all__ = [
     'PascalContextDataset59', 'ChaseDB1Dataset', 'DRIVEDataset', 'HRFDataset',
     'STAREDataset', 'DarkZurichDataset', 'NightDrivingDataset',
     'COCOStuffDataset', 'LoveDADataset', 'MultiImageMixDataset',
-    'iSAIDDataset', 'ISPRSDataset', 'PotsdamDataset', 'FaceOccludedDataset'
+    'iSAIDDataset', 'ISPRSDataset', 'PotsdamDataset', 'FaceOccludedDataset', 'SUADDDataset'
 ]
diff --git a/mmseg/datasets/suadd23.py b/mmseg/datasets/suadd23.py
new file mode 100644
index 0000000..4714098
--- /dev/null
+++ b/mmseg/datasets/suadd23.py
@@ -0,0 +1,124 @@
+import os
+import numpy as np
+from PIL import Image
+
+from mmseg.datasets.builder import DATASETS
+from mmseg.datasets.custom import CustomDataset
+
+@DATASETS.register_module()
+class SUADDDataset(CustomDataset):
+
+    CLASSES = ( "WATER",
+                "ASPHALT",
+                "GRASS",
+                "HUMAN",
+                "ANIMAL",
+                "HIGH_VEGETATION",
+                "GROUND_VEHICLE",
+                "FACADE",
+                "WIRE",
+                "GARDEN_FURNITURE",
+                "CONCRETE",
+                "ROOF",
+                "GRAVEL",
+                "SOIL",
+                "PRIMEAIR_PATTERN",
+                "SNOW")
+                
+    PALETTE = \
+       ([ 148, 218, 255 ],  # light blue
+        [  85,  85,  85 ],  # almost black
+        [ 200, 219, 190 ],  # light green
+        [ 166, 133, 226 ],  # purple    
+        [ 255, 171, 225 ],  # pink
+        [  40, 150, 114 ],  # green
+        [ 234, 144, 133 ],  # orange
+        [  89,  82,  96 ],  # dark gray
+        [ 255, 255,   0 ],  # yellow
+        [ 110,  87, 121 ],  # dark purple
+        [ 205, 201, 195 ],  # light gray
+        [ 212,  80, 121 ],  # medium red
+        [ 159, 135, 114 ],  # light brown
+        [ 102,  90,  72 ],  # dark brown
+        [ 255, 255, 102 ],  # bright yellow
+        [ 251, 247, 240 ])  # almost white
+
+    def __init__(self, split=None, **kwargs):
+        super().__init__(img_suffix='.png', 
+                         seg_map_suffix='.png', 
+                         reduce_zero_label=False,
+                         split=split, 
+                         ignore_index=255, 
+                         **kwargs)
+        
+    def format_results(self,
+                       results,
+                       imgfile_prefix,
+                       indices=None):
+        """Format the results into dir (standard format for Cityscapes
+        evaluation).
+
+        Args:
+            results (list): Testing results of the dataset.
+            imgfile_prefix (str): The prefix of images files. It
+                includes the file path and the prefix of filename, e.g.,
+                "a/b/prefix".
+            indices (list[int], optional): Indices of input results,
+                if not set, all the indices of the dataset will be used.
+                Default: None.
+
+        Returns:
+            tuple: (result_files, tmp_dir), result_files is a list containing
+                the image paths, tmp_dir is the temporal directory created
+                for saving json/png files when img_prefix is not specified.
+        """
+        if indices is None:
+            indices = list(range(len(self)))
+
+        assert isinstance(results, list), 'results must be a list.'
+        assert isinstance(indices, list), 'indices must be a list.'
+
+        result_files = self.results2img(results, imgfile_prefix,indices)
+
+        return result_files
+    
+    def results2img(self, results, imgfile_prefix, indices=None):
+        """Write the segmentation results to images.
+
+        Args:
+            results (list[ndarray]): Testing results of the
+                dataset.
+            imgfile_prefix (str): The filename prefix of the png files.
+                If the prefix is "somepath/xxx",
+                the png files will be named "somepath/xxx.png".
+            to_label_id (bool): whether convert output to label_id for
+                submission.
+            indices (list[int], optional): Indices of input results,
+                if not set, all the indices of the dataset will be used.
+                Default: None.
+
+        Returns:
+            list[str: str]: result txt files which contains corresponding
+            semantic segmentation images.
+        """
+        if indices is None:
+            indices = list(range(len(self)))
+
+        os.makedirs(imgfile_prefix, exist_ok=True)
+        result_files = []
+        for result, idx in zip(results, indices):
+            #result = self._convert_to_label_id(result)
+            filename = self.img_infos[idx]['filename']
+            basename = os.path.splitext(os.path.basename(filename))[0]
+
+            png_filename = os.path.join(imgfile_prefix, f'{basename}.png')
+
+            output = Image.fromarray(result.astype(np.uint8)).convert('P')
+            palette = np.zeros((len(self.CLASSES), 3), dtype=np.uint8)
+            for label_id in range(0, len(self.CLASSES)):
+                palette[label_id] = self.PALETTE[label_id]
+
+            output.putpalette(palette)
+            output.save(png_filename)
+            result_files.append(png_filename)
+        return result_files
\ No newline at end of file
